{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6758764,"sourceType":"datasetVersion","datasetId":3890483}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Importing Libraries</h1>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image\nimport os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2\nimport matplotlib.pyplot as plt\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-29T08:21:46.217871Z","iopub.execute_input":"2023-10-29T08:21:46.218208Z","iopub.status.idle":"2023-10-29T08:21:53.468766Z","shell.execute_reply.started":"2023-10-29T08:21:46.218183Z","shell.execute_reply":"2023-10-29T08:21:53.467994Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Reading The Images Paths and label</h1>","metadata":{}},{"cell_type":"code","source":"# Read the CSV file and split lines based on whitespace\ncsv_path = \"/kaggle/input/defective-solar-cells/elpv-dataset-master/labels.csv\"\nimages_folder = \"/kaggle/input/defective-solar-cells/elpv-dataset-master\"\n\nwith open(csv_path, \"r\") as file:\n    lines = file.read().splitlines()\n\n# Split each line into filename, label, and type\ndata = []\nfor line in lines:\n    parts = line.split()\n    if len(parts) == 3:\n        filename, label, _ = parts\n        data.append(\n            (os.path.join(images_folder, filename),\n            0 if float(label) <= 0.3333333333333333 else (1 if float(label) >= 0.6666666666666666 else int(label)))\n        )","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:21:53.47047Z","iopub.execute_input":"2023-10-29T08:21:53.471409Z","iopub.status.idle":"2023-10-29T08:21:53.496848Z","shell.execute_reply.started":"2023-10-29T08:21:53.471374Z","shell.execute_reply":"2023-10-29T08:21:53.496189Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Loading Images in Arrays</h1>","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 224\n\n# Load images and labels \nimages = []\nlabels = []\n\nfor image_path, label in data:\n    image = Image.open(image_path)\n#     image = image.convert(\"RGB\")\n    image = image.resize((IMG_SIZE, IMG_SIZE))\n    image = np.array(image)\n    images.append(image)\n    labels.append(label)\n    \n# Convert the lists dataframe\n# dataset_df = pd.DataFrame({'Image': images, 'Label': labels})\n\n# Convert the lists to numpy arrays\nimages = np.array(images).reshape(-1, 224, 224, 1)\nlabels = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:21:55.948553Z","iopub.execute_input":"2023-10-29T08:21:55.94926Z","iopub.status.idle":"2023-10-29T08:22:17.440133Z","shell.execute_reply.started":"2023-10-29T08:21:55.94923Z","shell.execute_reply":"2023-10-29T08:22:17.439347Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Some insights about the dataset</h1>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\npd.DataFrame(labels).value_counts().plot(kind='bar')\nplt.title('Data Class Distribution')\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-28T22:30:18.992375Z","iopub.execute_input":"2023-10-28T22:30:18.993221Z","iopub.status.idle":"2023-10-28T22:30:19.296466Z","shell.execute_reply.started":"2023-10-28T22:30:18.993187Z","shell.execute_reply":"2023-10-28T22:30:19.295581Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Balance Data</h1>","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Reshape the 4D image data into a 2D format\nnum_samples, img_height, img_width, num_channels = images.shape\nimages_2d = images.reshape((num_samples, img_height * img_width * num_channels))\n\n# Apply SMOTE to the 2D data\nsmote = SMOTE(sampling_strategy='auto', random_state=42)\nimages_resampled_2d, labels_resampled = smote.fit_resample(images_2d, labels)\n\n# Reshape the resampled 2D data back to 4D format\nimages_resampled = images_resampled_2d.reshape((-1, img_height, img_width, num_channels))\n\nimages = images_resampled\nlabels = labels_resampled","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:22:17.441918Z","iopub.execute_input":"2023-10-29T08:22:17.442545Z","iopub.status.idle":"2023-10-29T08:22:18.980975Z","shell.execute_reply.started":"2023-10-29T08:22:17.442511Z","shell.execute_reply":"2023-10-29T08:22:18.980107Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\npd.DataFrame(labels).value_counts().plot(kind='bar')\nplt.title('Data Class Distribution')\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-28T23:08:04.989872Z","iopub.execute_input":"2023-10-28T23:08:04.990672Z","iopub.status.idle":"2023-10-28T23:08:05.2513Z","shell.execute_reply.started":"2023-10-28T23:08:04.990638Z","shell.execute_reply":"2023-10-28T23:08:05.250391Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display some sample images\n# Generate 9 random indices\nsample_indices = random.sample(range(len(images)), 9)\n\n# Create a 3x3 grid of subplots for plotting the images\nplt.figure(figsize=(10, 10))\nplt.suptitle(\"Some Sample Images\", fontsize=16)\n\nfor i, idx in enumerate(sample_indices):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(images[idx], cmap='gray')  # Assuming images are grayscale; use 'cmap' based on your data\n    plt.title(f\"Label: {labels[idx]}\")\n    plt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-28T23:08:10.854253Z","iopub.execute_input":"2023-10-28T23:08:10.855024Z","iopub.status.idle":"2023-10-28T23:08:11.677282Z","shell.execute_reply.started":"2023-10-28T23:08:10.854991Z","shell.execute_reply":"2023-10-28T23:08:11.676317Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Enhancing Images</h1>","metadata":{}},{"cell_type":"code","source":"# Define the image preprocessing function\ndef image_preprocessing(img):\n    # equalize\n    img = img.astype('uint8')\n    clahe = cv2.createCLAHE(tileGridSize=(8, 8))\n    img = clahe.apply(img)\n    img = np.expand_dims(img, 2)\n    \n#     # Apply Sobel filters to detect vertical and diagonal edges\n#     vertical_edge = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n#     diagonal_edge = cv2.Sobel(img, cv2.CV_64F, 1, 1, ksize=3)\n\n#     # Combine the edges into one image\n#     combined_edges = cv2.addWeighted(vertical_edge, 0.5, diagonal_edge, 0.5, 0)\n\n#     # Normalize the values to the range [0, 255]\n#     combined_edges = cv2.normalize(combined_edges, None, 0, 255, cv2.NORM_MINMAX)\n\n#     # Convert to 8-bit unsigned integer format\n#     combined_edges = np.uint8(combined_edges)\n#     return combined_edges\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:22:18.982004Z","iopub.execute_input":"2023-10-29T08:22:18.982485Z","iopub.status.idle":"2023-10-29T08:22:18.988207Z","shell.execute_reply.started":"2023-10-29T08:22:18.982461Z","shell.execute_reply":"2023-10-29T08:22:18.987233Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply the equalize function to each image in 'images'\nenhanced_images = np.array([image_preprocessing(img) for img in images])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:22:18.990085Z","iopub.execute_input":"2023-10-29T08:22:18.990367Z","iopub.status.idle":"2023-10-29T08:22:19.90905Z","shell.execute_reply.started":"2023-10-29T08:22:18.990333Z","shell.execute_reply":"2023-10-29T08:22:19.908241Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Show Enhanced Images</h1>","metadata":{}},{"cell_type":"code","source":"# Display some sample images\n\n# Create a 3x3 grid of subplots for plotting the images and their enhanced versions\nplt.figure(figsize=(15, 15))\nplt.suptitle(\"Some Sample Images and Enhanced Versions\", fontsize=16)\n\nfor i, idx in enumerate(sample_indices):\n    # Plot the original image\n    plt.subplot(3, 6, 2 * i + 1)\n    plt.imshow(images[idx], cmap='gray')  # Assuming images are grayscale; use 'cmap' based on your data\n    plt.title(f\"Label: {labels[idx]}\")\n    plt.axis('off')\n\n    # Plot the enhanced version beside the original image\n    plt.subplot(3, 6, 2 * i + 2)\n    plt.imshow(enhanced_images[idx], cmap='gray')  # Assuming enhanced_images are grayscale; use 'cmap' based on your data\n    plt.title(\"Enhanced\")\n    plt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T00:02:15.334627Z","iopub.execute_input":"2023-10-29T00:02:15.334993Z","iopub.status.idle":"2023-10-29T00:02:16.72011Z","shell.execute_reply.started":"2023-10-29T00:02:15.334962Z","shell.execute_reply":"2023-10-29T00:02:16.719217Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Divide Dataset to Train and Test Data</h1>","metadata":{}},{"cell_type":"code","source":"# Split the data generator into training and validation generators\ntrain_images, test_images, train_labels, test_labels = train_test_split(enhanced_images, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:22:19.910173Z","iopub.execute_input":"2023-10-29T08:22:19.910443Z","iopub.status.idle":"2023-10-29T08:22:19.965463Z","shell.execute_reply.started":"2023-10-29T08:22:19.910419Z","shell.execute_reply":"2023-10-29T08:22:19.964651Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Data Augmentation</h1>","metadata":{}},{"cell_type":"code","source":"# batch_size = 32\n\n# datagen = ImageDataGenerator(\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     brightness_range=[0.5, 1.5],\n#     horizontal_flip=True,\n#     vertical_flip=True,\n#     fill_mode='nearest',\n# )\n\n# # Apply data augmentation to train data\n# train_datagen = datagen.flow(train_images, train_labels, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-28T22:36:45.840238Z","iopub.execute_input":"2023-10-28T22:36:45.841145Z","iopub.status.idle":"2023-10-28T22:36:45.985594Z","shell.execute_reply.started":"2023-10-28T22:36:45.841112Z","shell.execute_reply":"2023-10-28T22:36:45.984734Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Building The model</h1>","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\n# model.add(Conv2D(8, kernel_size=5, padding='same',  input_shape=(IMG_SIZE, IMG_SIZE, 1), kernel_regularizer=l2(0.001)))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPool2D(2, padding='same'))\n# model.add(Dropout(0.3))\n\n# model.add(Conv2D(16, kernel_size=3, padding='same', kernel_regularizer=l2(0.001)))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPool2D(2, padding='same'))\n# model.add(Dropout(0.3))\n\n# model.add(Conv2D(32, kernel_size=3, padding='same', kernel_regularizer=l2(0.02), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPool2D(2, padding='same'))\n# model.add(Dropout(0.3))\n\nmodel.add(Conv2D(64, kernel_size=3, padding='same', kernel_regularizer=l2(0.02), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(2, padding='same'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(128, kernel_size=3, padding='same', kernel_regularizer=l2(0.02)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(2, padding='same'))\nmodel.add(Dropout(0.3))\n\n# Output Layer\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n# model.summary()\nfrom keras.utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-10-29T08:22:20.736388Z","iopub.execute_input":"2023-10-29T08:22:20.737096Z","iopub.status.idle":"2023-10-29T08:22:23.835189Z","shell.execute_reply.started":"2023-10-29T08:22:20.737065Z","shell.execute_reply":"2023-10-29T08:22:23.834294Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Early stopping to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=2, restore_best_weights=True)\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:22:27.992466Z","iopub.execute_input":"2023-10-29T08:22:27.993481Z","iopub.status.idle":"2023-10-29T08:22:28.015833Z","shell.execute_reply.started":"2023-10-29T08:22:27.993442Z","shell.execute_reply":"2023-10-29T08:22:28.014989Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the number of epochs\nnum_epochs = 200\nbatch_size = 16\n\n# Start training the model\nhistory = model.fit(\n    train_images,\n    train_labels,\n    epochs=num_epochs,\n    batch_size=batch_size,\n    validation_data=(test_images, test_labels),\n    callbacks=[early_stopping]\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-10-29T08:22:30.559907Z","iopub.execute_input":"2023-10-29T08:22:30.560825Z","iopub.status.idle":"2023-10-29T08:31:29.916612Z","shell.execute_reply.started":"2023-10-29T08:22:30.560789Z","shell.execute_reply":"2023-10-29T08:31:29.915623Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Training History</h1>","metadata":{}},{"cell_type":"code","source":"# Access the training history\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Create subplots for loss and accuracy\nplt.figure(figsize=(12, 4))\n# Plot training and validation loss\nplt.subplot(1, 2, 1)\nplt.plot(train_loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n# Plot training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:31:49.880346Z","iopub.execute_input":"2023-10-29T08:31:49.881162Z","iopub.status.idle":"2023-10-29T08:31:50.515634Z","shell.execute_reply.started":"2023-10-29T08:31:49.881129Z","shell.execute_reply":"2023-10-29T08:31:50.514724Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Model Evaluation</h1>","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T08:32:07.648058Z","iopub.execute_input":"2023-10-29T08:32:07.648856Z","iopub.status.idle":"2023-10-29T08:32:08.20916Z","shell.execute_reply.started":"2023-10-29T08:32:07.648826Z","shell.execute_reply":"2023-10-29T08:32:08.208367Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Transfer Learning</h1>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetV2L\n\nbase_model = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\nmodel = Sequential()\nmodel.add(base_model)  # Add the pre-trained model\nmodel.add(Flatten())  # Flatten the output from the pre-trained model\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))  # Output layer\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T09:15:02.901808Z","iopub.execute_input":"2023-10-29T09:15:02.902663Z","iopub.status.idle":"2023-10-29T09:15:15.504087Z","shell.execute_reply.started":"2023-10-29T09:15:02.90263Z","shell.execute_reply":"2023-10-29T09:15:15.503079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create an empty RGB array with shape (num_samples, IMG_SIZE, IMG_SIZE, 3)\ntrain_images_rgb = np.empty((train_images.shape[0], IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n\n# Duplicate the single-channel images into all three color channels\ntrain_images_rgb[:, :, :, 0] = train_images[:, :, :, 0]\ntrain_images_rgb[:, :, :, 1] = train_images[:, :, :, 0]\ntrain_images_rgb[:, :, :, 2] = train_images[:, :, :, 0]\n\n# Create an empty RGB array with shape (num_samples, IMG_SIZE, IMG_SIZE, 3)\ntest_images_rgb = np.empty((test_images.shape[0], IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n\n# Duplicate the single-channel images into all three color channels\ntest_images_rgb[:, :, :, 0] = test_images[:, :, :, 0]\ntest_images_rgb[:, :, :, 1] = test_images[:, :, :, 0]\ntest_images_rgb[:, :, :, 2] = test_images[:, :, :, 0]","metadata":{"execution":{"iopub.status.busy":"2023-10-29T09:15:15.505851Z","iopub.execute_input":"2023-10-29T09:15:15.506146Z","iopub.status.idle":"2023-10-29T09:15:15.857714Z","shell.execute_reply.started":"2023-10-29T09:15:15.506121Z","shell.execute_reply":"2023-10-29T09:15:15.856673Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 100\n\nhistory = model.fit(\n    train_images_rgb,\n    train_labels,\n    epochs=num_epochs,\n    validation_data=(test_images_rgb, test_labels),\n    batch_size=batch_size,\n    callbacks=[early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T09:15:15.859059Z","iopub.execute_input":"2023-10-29T09:15:15.859702Z","iopub.status.idle":"2023-10-29T10:01:39.223872Z","shell.execute_reply.started":"2023-10-29T09:15:15.859665Z","shell.execute_reply":"2023-10-29T10:01:39.222813Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Access the training history\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Create subplots for loss and accuracy\nplt.figure(figsize=(12, 4))\n# Plot training and validation loss\nplt.subplot(1, 2, 1)\nplt.plot(train_loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n# Plot training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:01:39.225975Z","iopub.execute_input":"2023-10-29T10:01:39.226273Z","iopub.status.idle":"2023-10-29T10:01:39.850044Z","shell.execute_reply.started":"2023-10-29T10:01:39.226247Z","shell.execute_reply":"2023-10-29T10:01:39.848976Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"color:#e8710a\">Model Evaluation</h1>","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_images_rgb, test_labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:01:39.851384Z","iopub.execute_input":"2023-10-29T10:01:39.851697Z","iopub.status.idle":"2023-10-29T10:01:44.968821Z","shell.execute_reply.started":"2023-10-29T10:01:39.851669Z","shell.execute_reply":"2023-10-29T10:01:44.967829Z"},"trusted":true},"outputs":[],"execution_count":null}]}